{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from matplotlib import pyplot\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CSV_file')\n",
    "\n",
    "# train_test set splitting (stratified with day of the year and the vineyards)\n",
    "X, y = df.iloc[:,1:].values, df.iloc[:,0].values\n",
    "X_train_o, X_test_o, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                    random_state=19, stratify=df.iloc[:,2])\n",
    "np.mean(y_train), np.mean(y_test), np.std(y_train), np.std(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler_st = StandardScaler()\n",
    "X_train_st = scaler_st.fit_transform(X_train_o[:,1:])\n",
    "X_test_st = scaler_st.transform(X_test_o[:,1:])\n",
    "X_train_st = np.insert(X_train_st, 0, X_train_o[:,0], axis=1)\n",
    "X_test_st = np.insert(X_test_st, 0, X_test_o[:,0], axis=1)\n",
    "\n",
    "# make train_test array back to dataframe\n",
    "df_train = pd.DataFrame(X_train_st)\n",
    "df_train.columns = df.columns[1:]\n",
    "df_test = pd.DataFrame(X_test_st)\n",
    "df_test.columns = df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make combinations of training sets \n",
    "G1 = [list(df_train['d_RHmean']),list(df_train['d_Rtotal']),\n",
    "      list(df_train['zero'])]\n",
    "G2 = [list(df_train['Slope']),list(df_train['zero'])]\n",
    "G3 = [list(df_train['DOY']),list(df_train['w_IRtotal']),\n",
    "      list(df_train['zero'])]\n",
    "G4 = [list(df_train['w_WSmean']),list(df_train['d_WSmean']),\n",
    "      list(df_train['d_IRtotal']),list(df_train['zero'])]\n",
    "G5 = [list(df_train['TCARI']),list(df_train['d_Tmean']),\n",
    "      list(df_train['w_RHmean']),list(df_train['w_Rtotal']),\n",
    "      list(df_train['zero'])]\n",
    "G6 = [list(df_train['EC']),list(df_train['zero'])]\n",
    "G7 = [list(df_train['Elevation']),list(df_train['zero'])]\n",
    "G8 = [list(df_train['w_Tmean']),list(df_train['zero'])]\n",
    "combi_train = [G1,G2,G3,G4,G5,G6,G7,G8]\n",
    "data_combi_train = list(product(*combi_train))\n",
    "index_train = ['{}'.format(i) for i in range(1, len(data_combi_train)+1)]\n",
    "df_combi_train = pd.DataFrame(data_combi_train, index=index_train,\n",
    "                              columns=['G{}'.format(i) for i in range(1,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make combinations of test sets \n",
    "G1_ = [list(df_test['d_RHmean']),list(df_test['d_Rtotal']),\n",
    "      list(df_test['zero'])]\n",
    "G2_ = [list(df_test['Slope']),list(df_test['zero'])]\n",
    "G3_ = [list(df_test['DOY']),list(df_test['w_IRtotal']),\n",
    "      list(df_test['zero'])]\n",
    "G4_ = [list(df_test['w_WSmean']),list(df_test['d_WSmean']),\n",
    "      list(df_test['d_IRtotal']),list(df_test['zero'])]\n",
    "G5_ = [list(df_test['TCARI']),list(df_test['d_Tmean']),\n",
    "      list(df_test['w_RHmean']),list(df_test['w_Rtotal']),\n",
    "      list(df_test['zero'])]\n",
    "G6_ = [list(df_test['EC']),list(df_test['zero'])]\n",
    "G7_ = [list(df_test['Elevation']),list(df_test['zero'])]\n",
    "G8_ = [list(df_test['w_Tmean']),list(df_test['zero'])]\n",
    "combi_test = [G1_,G2_,G3_,G4_,G5_,G6_,G7_,G8_]\n",
    "data_combi_test = list(product(*combi_test))\n",
    "index_test = ['{}'.format(i) for i in range(1, len(data_combi_test)+1)]\n",
    "df_combi_test = pd.DataFrame(data_combi_test, index=index_test,\n",
    "                              columns=['G{}'.format(i) for i in range(1,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run regression algorithms to determine the best combination of features based on RMSE\n",
    "# Elastic net\n",
    "en_list2 = []\n",
    "for i in range(1, len(data_combi_train)+1):\n",
    "    # stack the normal array to be training set of each combination\n",
    "    X_train_extract = np.stack(df_combi_train.iloc[i-1,:],axis = 1)\n",
    "    X_test_extract = np.stack(df_combi_test.iloc[i-1,:],axis = 1)\n",
    "    # Elastic net\n",
    "    en = ElasticNet(max_iter=10000, tol=0.001, warm_start=True)\n",
    "    en_para = {'alpha':[1e-2, 1e-1, 1, 10, 100],\n",
    "               'l1_ratio':np.arange(0.1, 1, 0.1)}\n",
    "    en_gs = GridSearchCV(en, en_para, cv = 10, scoring='r2', n_jobs=8)\n",
    "    en_gs.fit(X_train_extract, y_train)\n",
    "    en_train_r2 = en_gs.score(X_train_extract, y_train)\n",
    "    en_test_r2 = en_gs.score(X_test_extract, y_test)\n",
    "    en_test_rmse = mean_squared_error(y_test, en_gs.predict(X_test_extract), \n",
    "                                      squared=False)\n",
    "    en_output = [i,en_train_r2, en_test_r2, en_test_rmse]\n",
    "    en_list2.append(en_output)\n",
    "df_en2 = pd.DataFrame(en_list2, columns =['combination','r2_train','r2_test','rmse_test'])\n",
    "df_en2.to_csv('CSV_EN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest regression\n",
    "rf_list2 = []\n",
    "for i in range(1, len(data_combi_train)+1):\n",
    "    # stack the normal array to be training set of each combination\n",
    "    X_train_extract = np.stack(df_combi_train.iloc[i-1,:],axis = 1)\n",
    "    X_test_extract = np.stack(df_combi_test.iloc[i-1,:],axis = 1)\n",
    "    # Random forest regression\n",
    "    rf = RandomForestRegressor(max_depth=2, n_estimators=100, \n",
    "                               random_state=0, n_jobs=8)\n",
    "    rf_para = {'max_features':['auto', 'sqrt', 'log2']}\n",
    "    rf_gs = GridSearchCV(rf, rf_para, cv = 10, scoring='r2', n_jobs=8)\n",
    "    rf_gs.fit(X_train_extract, y_train)\n",
    "    rf_train_r2 = rf_gs.score(X_train_extract, y_train)\n",
    "    rf_test_r2 = rf_gs.score(X_test_extract, y_test)\n",
    "    rf_test_rmse = mean_squared_error(y_test, rf_gs.predict(X_test_extract), \n",
    "                                      squared=False)\n",
    "    rf_output = [i,rf_train_r2, rf_test_r2, rf_test_rmse]\n",
    "    rf_list2.append(rf_output)\n",
    "df_rf2 = pd.DataFrame(rf_list2, columns =['combination','r2_train','r2_test','rmse_test'])\n",
    "df_rf2.to_csv('CSV_RFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector regression\n",
    "svr_list2 = []\n",
    "for i in range(1, len(data_combi_train)+1):\n",
    "    # stack the normal array to be training set of each combination\n",
    "    X_train_extract = np.stack(df_combi_train.iloc[i-1,:], axis = 1)\n",
    "    X_test_extract = np.stack(df_combi_test.iloc[i-1,:], axis = 1)\n",
    "    # Support vector regression\n",
    "    svr = SVR()\n",
    "    svr_para = {'kernel':['linear','poly','rbf'], 'C':[0.01,0.1,1,10,100], \n",
    "                        'gamma':['scale','auto'], 'epsilon':[0.1,0.5,0.9]}\n",
    "    svr_gs = GridSearchCV(svr, svr_para, cv = 10, scoring='r2', n_jobs=8)\n",
    "    svr_gs.fit(X_train_extract, y_train)\n",
    "    svr_train_r2 = svr_gs.score(X_train_extract, y_train)\n",
    "    svr_test_r2 = svr_gs.score(X_test_extract, y_test)\n",
    "    svr_test_rmse = mean_squared_error(y_test, svr_gs.predict(X_test_extract),\n",
    "                                       squared=False)\n",
    "    svr_output = [i,svr_train_r2, svr_test_r2, svr_test_rmse]\n",
    "    svr_list2.append(svr_output)\n",
    "df_svr2 = pd.DataFrame(svr_list2, columns =['combination','r2_train','r2_test','rmse_test'])\n",
    "df_svr2.to_csv('CSV_SVR')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
