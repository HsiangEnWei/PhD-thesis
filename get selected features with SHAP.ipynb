{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from matplotlib import pyplot\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CSV_file')\n",
    "\n",
    "# train_test set splitting (stratified with day of the year and the vineyards)\n",
    "X, y = df.iloc[:,1:].values, df.iloc[:,0].values\n",
    "X_train_o, X_test_o, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                    random_state=19, stratify=df.iloc[:,2])\n",
    "\n",
    "# Standardization\n",
    "scaler_st = StandardScaler()\n",
    "X_train_st = scaler_st.fit_transform(X_train_o[:,1:])\n",
    "X_test_st = scaler_st.transform(X_test_o[:,1:])\n",
    "X_train_st = np.insert(X_train_st, 0, X_train_o[:,0], axis=1)\n",
    "X_test_st = np.insert(X_test_st, 0, X_test_o[:,0], axis=1)\n",
    "\n",
    "# make train_test array back to dataframe\n",
    "df_train = pd.DataFrame(X_train_st)\n",
    "df_train.columns = df.columns[1:]\n",
    "df_test = pd.DataFrame(X_test_st)\n",
    "df_test.columns = df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make combinations of training sets \n",
    "G1 = [list(df_train['d_RHmean']),list(df_train['d_Rtotal']),\n",
    "      list(df_train['zero'])]\n",
    "G2 = [list(df_train['Slope']),list(df_train['zero'])]\n",
    "G3 = [list(df_train['DOY']),list(df_train['w_IRtotal']),\n",
    "      list(df_train['zero'])]\n",
    "G4 = [list(df_train['w_WSmean']),list(df_train['d_WSmean']),\n",
    "      list(df_train['d_IRtotal']),list(df_train['zero'])]\n",
    "G5 = [list(df_train['TCARI']),list(df_train['d_Tmean']),\n",
    "      list(df_train['w_RHmean']),list(df_train['w_Rtotal']),\n",
    "      list(df_train['zero'])]\n",
    "G6 = [list(df_train['ECa']),list(df_train['zero'])]\n",
    "G7 = [list(df_train['Elevation']),list(df_train['zero'])]\n",
    "G8 = [list(df_train['w_Tmean']),list(df_train['zero'])]\n",
    "combi_train = [G1,G2,G3,G4,G5,G6,G7,G8]\n",
    "data_combi_train = list(product(*combi_train))\n",
    "index_train = ['{}'.format(i) for i in range(1, len(data_combi_train)+1)]\n",
    "df_combi_train = pd.DataFrame(data_combi_train, index=index_train,\n",
    "                              columns=['G{}'.format(i) for i in range(1,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make combinations of test sets \n",
    "G1_ = [list(df_test['d_RHmean']),list(df_test['d_Rtotal']),\n",
    "      list(df_test['zero'])]\n",
    "G2_ = [list(df_test['Slope']),list(df_test['zero'])]\n",
    "G3_ = [list(df_test['DOY']),list(df_test['w_IRtotal']),\n",
    "      list(df_test['zero'])]\n",
    "G4_ = [list(df_test['w_WSmean']),list(df_test['d_WSmean']),\n",
    "      list(df_test['d_IRtotal']),list(df_test['zero'])]\n",
    "G5_ = [list(df_test['TCARI']),list(df_test['d_Tmean']),\n",
    "      list(df_test['w_RHmean']),list(df_test['w_Rtotal']),\n",
    "      list(df_test['zero'])]\n",
    "G6_ = [list(df_test['ECa']),list(df_test['zero'])]\n",
    "G7_ = [list(df_test['Elevation']),list(df_test['zero'])]\n",
    "G8_ = [list(df_test['w_Tmean']),list(df_test['zero'])]\n",
    "combi_test = [G1_,G2_,G3_,G4_,G5_,G6_,G7_,G8_]\n",
    "data_combi_test = list(product(*combi_test))\n",
    "index_test = ['{}'.format(i) for i in range(1, len(data_combi_test)+1)]\n",
    "df_combi_test = pd.DataFrame(data_combi_test, index=index_test,\n",
    "                              columns=['G{}'.format(i) for i in range(1,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the selected features \n",
    "pd.set_option(\"display.precision\", 5)\n",
    "feature_list = [] \n",
    "for i in [2526]: #combination No. of the model with the best performance\n",
    "    X_train_extract = np.stack(df_combi_train.iloc[i-1,:],axis = 1)\n",
    "    X_test_extract = np.stack(df_combi_test.iloc[i-1,:],axis = 1)\n",
    "    \n",
    "    svr = SVR()\n",
    "    svr_para = {'kernel':['linear','poly','rbf'], 'C':[0.01,0.1,1,10,100], \n",
    "                        'gamma':['scale','auto'], 'epsilon':[0.1,0.5,0.9]}\n",
    "    svr_gs = GridSearchCV(svr, svr_para, cv = 10, scoring='r2', n_jobs=8)\n",
    "    svr_gs.fit(X_train_extract, y_train)\n",
    "    svr_train_r2 = svr_gs.score(X_train_extract, y_train)\n",
    "    svr_test_r2 = svr_gs.score(X_test_extract, y_test)\n",
    "    svr_test_rmse = mean_squared_error(y_test, svr_gs.predict(X_test_extract),\n",
    "                                       squared=False)\n",
    "    feature = [i,svr_train_r2, svr_test_r2, svr_test_rmse]+list(data_combi_r[i-1]) #the last part: tuple to list\n",
    "    feature_list.append(feature)\n",
    "    df_feature = pd.DataFrame(feature_list, columns=['combination','train_r2','test_r2','test_rmse',\n",
    "                                                     '1','2','3','4','5','6','7','8'])\n",
    "df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make regression graph\n",
    "X_train_extract = np.stack(df_combi_train.iloc[j-1,:],axis = 1)\n",
    "X_test_extract = np.stack(df_combi_test.iloc[j-1,:],axis = 1)\n",
    "\n",
    "svr = SVR()\n",
    "svr_para = {'kernel':['linear','poly','rbf'], 'C':[0.01,0.1,1,10,100], \n",
    "                        'gamma':['scale','auto'], 'epsilon':[0.1,0.5,0.9]}\n",
    "svr_gs = GridSearchCV(svr, svr_para, cv = 10, scoring='r2', n_jobs=8)\n",
    "svr_gs.fit(X_train_extract, y_train)\n",
    "graph_x1 = svr_gs.predict(X_train_extract) \n",
    "graph_y1 = y_train\n",
    "graph_x2 = svr_gs.predict(X_test_extract) \n",
    "graph_y2 = y_test\n",
    "pyplot.figure(dpi=600)\n",
    "pyplot.plot([0,1400], [0,1400], 'r:')\n",
    "scatter1 = pyplot.scatter(graph_x1, graph_y1, s=5)\n",
    "scatter2 = pyplot.scatter(graph_x2, graph_y2, s=5)\n",
    "pyplot.legend((scatter1,scatter2), ('training set','test set'), loc='lower right')\n",
    "b, m = polyfit(graph_x.ravel(), graph_y, 1)\n",
    "pyplot.plot(graph_x, m*graph_x + b, 'b-')\n",
    "pyplot.ylabel('observed Ѱstem (kPa)')\n",
    "pyplot.xlabel('predicted Ѱstem (kPa)')\n",
    "pyplot.axis([0, 1400, 0, 1400])\n",
    "pyplot.savefig('plot_file',dpi=600)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHapley Additive exPlanations (SHAP) values for the best model\n",
    "X_train_extract = np.stack(df_combi_train.iloc[j-1,:],axis = 1)\n",
    "X_test_extract = np.stack(df_combi_test.iloc[j-1,:],axis = 1)\n",
    "\n",
    "svr = SVR()\n",
    "svr_para = {'kernel':['linear','poly','rbf'], 'C':[0.01,0.1,1,10,100], \n",
    "                        'gamma':['scale','auto'], 'epsilon':[0.1,0.5,0.9]}\n",
    "svr_gs = GridSearchCV(svr, svr_para, cv = 10, scoring='r2', n_jobs=8)\n",
    "svr_gs.fit(X_train_extract, y_train)\n",
    "explainer_svr = shap.KernelExplainer(svr_gs.predict, X_train_extract) \n",
    "df_st = pd.concat([df_train, df_test], ignore_index=True) # get total standardized data\n",
    "shap_svr = explainer_svr.shap_values(df_st[list(data_combi_r[j-1])]) # compute SHAP values for all observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary plot\n",
    "pyplot.figure(dpi=600)\n",
    "shap.summary_plot(shap_svr, df_st[list(data_combi_r[j-1])], max_display=3, \n",
    "                  show=False)\n",
    "pyplot.tight_layout()\n",
    "pyplot.savefig('plot_file', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary plot_bar\n",
    "pyplot.figure(dpi=600)\n",
    "shap.summary_plot(shap_svr, df_st[list(data_combi_r[j-1])], plot_type=\"bar\", \n",
    "                  max_display=3, show=False)\n",
    "pyplot.tight_layout()\n",
    "pyplot.savefig('plot_file', dpi=600)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
