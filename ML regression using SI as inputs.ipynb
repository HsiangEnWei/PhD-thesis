{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from matplotlib import pyplot\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CSV files which contain all simple ratio indices for each sample \n",
    "df1 = pd.read_csv('PhDdata/SI/CSV_file1')\n",
    "df2 = pd.read_csv('PhDdata/SI/CSV_file2')\n",
    "df = pd.concat([df1, df2], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose\n",
    "df_T = df.iloc[:,1:].transpose()\n",
    "df_T.columns = list(df['No'])\n",
    "df_T.insert(loc=2, column='No', value=range(85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with the mean value \n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_im = imputer.fit_transform(df_T)\n",
    "df_im = pd.DataFrame(df_im, columns = df_T.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test dataset splitting (stratified with day of the year and the vineyards)\n",
    "X, y = df_im.iloc[:,2:].values, df_im.iloc[:,0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=df_im.iloc[:,1])\n",
    "X_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler_st = StandardScaler()\n",
    "X_train_st = scaler_st.fit_transform(X_train[:,1:])\n",
    "X_test_st = scaler_st.transform(X_test[:,1:])\n",
    "X_train_st = np.insert(X_train_st, 0, X_train[:,0], axis=1)\n",
    "X_test_st = np.insert(X_test_st, 0, X_test[:,0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make traing dataset for Spearman correlation\n",
    "y_train_T = y_train.T.reshape(1,59)\n",
    "df_train = np.concatenate((X_train.T, y_train_T), axis=0)\n",
    "df_train = pd.DataFrame(df_train)\n",
    "df_train.iloc[:1021701].to_csv('CSV_file_train1', header=False, index=False)\n",
    "df_train.iloc[1021701:].to_csv('CSV_file_train2', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman correlation (threshold is 0.6)\n",
    "df_sp1 = pd.read_csv('CSV_file_train1', usecols = ['No','rho','t','p'], lineterminator='\\n')\n",
    "df_sp1 = df_sp1.iloc[:1021700,:]\n",
    "df_sp2 = pd.read_csv('CSV_file_train2', usecols = ['No','rho','t','p'], lineterminator='\\n')\n",
    "df_sp2 = df_sp2.iloc[:979300,:]\n",
    "df_sp = pd.concat([df_sp1, df_sp2], axis=0, sort=False)\n",
    "feature_pear = df_sp[df_sp['rho']<-0.6].append(df_sp[df_sp['rho']>0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carefully select the parameter range to prevent overfitting, then use these ranges for modeling\n",
    "# Partial least squares regression (use default scale = True for X, y)\n",
    "plsr_full_plsr = PLSRegression()\n",
    "para_full_plsr = {'n_components':[1,2,3,4,5,6,7,8,9,10]}\n",
    "gs_full_plsr = GridSearchCV(plsr_full_plsr, para_full_plsr, cv = 10, scoring='r2')\n",
    "gs_full_plsr.fit(X_train[:,1:], y_train)\n",
    "gs_full_plsr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_plsr_tune = PLSRegression(n_components=8) # change according to the best set of hyperparameter\n",
    "full_plsr_tune.fit(X_train[:,1:], y_train)\n",
    "r2_full_plsr_train = full_plsr_tune.score(X_train[:, 1:], y_train)\n",
    "r2_full_plsr = full_plsr_tune.score(X_test[:,1:], y_test)\n",
    "rmse_full_plsr = mean_squared_error(y_test, full_plsr_tune.predict(X_test[:,1:]), squared=False)\n",
    "r2_full_plsr_train, r2_full_plsr, rmse_full_plsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate variable importance in projection (VIP)\n",
    "def _calculate_vips(model):\n",
    "    t = model.x_scores_\n",
    "    w = model.x_weights_\n",
    "    q = model.y_loadings_\n",
    "    p, h = w.shape\n",
    "    vips = np.zeros((p,))\n",
    "    s = np.diag(np.matmul(np.matmul(np.matmul(t.T,t),q.T), q)).reshape(h, -1)\n",
    "    total_s = np.sum(s)\n",
    "    for i in range(p):\n",
    "        weight = np.array([ (w[i,j] / np.linalg.norm(w[:,j]))**2 for j in range(h) ])\n",
    "        vips[i] = np.sqrt(p*(np.matmul(s.T, weight))/total_s)\n",
    "    return vips\n",
    "VIP = _calculate_vips(full_plsr_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save VIP files\n",
    "VIP_pd = pd.DataFrame()\n",
    "VIP_pd['VIP'] = VIP\n",
    "VIP_pd['variable'] = df_im.columns[3:]\n",
    "VIP_pd[:1021701].to_csv('CSV_file_VIP1', header=False, index=False)\n",
    "VIP_pd[1021701:].to_csv('CSV_file_VIP2', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make regression graph\n",
    "graph_x = full_plsr_tune.predict(X_test[:,1:]) \n",
    "graph_y = y_test\n",
    "pyplot.figure(dpi=600)\n",
    "pyplot.plot([300,1400], [300,1400], 'r:')\n",
    "pyplot.scatter(graph_x, graph_y)\n",
    "b, m = polyfit(graph_x.ravel(), graph_y, 1)\n",
    "pyplot.plot(graph_x, m*graph_x + b, 'b-')\n",
    "pyplot.ylabel('predicted Ѱstem (kPa)')\n",
    "pyplot.xlabel('observed Ѱstem (kPa)')\n",
    "pyplot.axis([300, 1400, 300, 1400])\n",
    "pyplot.savefig('plot_file',dpi=600)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "rf_full_rf = RandomForestRegressor(max_depth=1, n_estimators=500, random_state=0, n_jobs=-1)\n",
    "para_full_rf = {'max_features':['auto', 'sqrt', 'log2']}\n",
    "gs_full_rf = GridSearchCV(rf_full_rf, para_full_rf, cv = 10, scoring='r2')\n",
    "gs_full_rf.fit(X_train[:,1:], y_train)\n",
    "gs_full_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_rf_tune = RandomForestRegressor(max_depth=1, max_features='sqrt', n_estimators=500, n_jobs=-1, random_state=0) # change according to the best set of hyperparameter\n",
    "full_rf_tune.fit(X_train[:,1:], y_train)\n",
    "r2_full_rf_train = full_rf_tune.score(X_train[:,1:], y_train)\n",
    "r2_full_rf = full_rf_tune.score(X_test[:, 1:], y_test)\n",
    "rmse_full_rf = mean_squared_error(y_test, full_rf_tune.predict(X_test[:, 1:]), squared=False)\n",
    "r2_full_rf_train, r2_full_rf, rmse_full_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate feature importance\n",
    "rf_fi_pd = pd.DataFrame()\n",
    "rf_fi_pd['FI'] = rfe_rf_tune.feature_importances_\n",
    "rf_fi_pd['variable'] = df_im.iloc[:,3:].columns[rfe_rf.get_support()]\n",
    "rf_fi_pd.to_csv('CSV_file_FI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector regression\n",
    "svr_full_svr = SVR()\n",
    "para_full_svr = {'C':[0.1,0.5,1,5,10,50,100,500,1000], 'kernel':['linear','poly','rbf','sigmoid'], 'gamma':['scale','auto'], \n",
    "                 'epsilon':[0.1,0.3,0.5,0.7,0.9]}\n",
    "gs_full_svr = GridSearchCV(svr_full_svr, para_full_svr, cv = 10, scoring='r2')\n",
    "gs_full_svr.fit(X_train_st[:,1:], y_train)\n",
    "gs_full_svr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_svr_tune = SVR(C=50, kernel='sigmoid') # change according to the best set of hyperparameter\n",
    "full_svr_tune.fit(X_train_st[:,1:], y_train)\n",
    "r2_full_svr_train = full_svr_tune.score(X_train_st[:,1:], y_train)\n",
    "r2_full_svr = full_svr_tune.score(X_test_st[:, 1:], y_test)\n",
    "rmse_full_svr = mean_squared_error(y_test, full_svr_tune.predict(X_test_st[:, 1:]), squared=False)\n",
    "r2_full_svr_train, r2_full_svr, rmse_full_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coefficient weight\n",
    "svr_coef_pd = pd.DataFrame()\n",
    "svr_coef_pd['coef'] = rfe_svr_tune.coef_.ravel()\n",
    "svr_coef_pd['variable'] = df_im.iloc[:, 3:].columns[rfe_svr.get_support()]                                       \n",
    "svr_coef_pd.to_csv('CSV_file_CW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "pickle.dump(gs_pear_rf, open('file_name', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
